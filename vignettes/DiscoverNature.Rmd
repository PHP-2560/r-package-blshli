---
title: "Performing literature searches with DiscoverNature"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Performing literature searches with discover nature}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction
Nature is one of the world's leading scientific journal publication platforms. It was founded by Norman Lockyer and generously endorsed by Daniel and Alexander Macmillan in 1869. According to Wikipedia, the journal originated in Britain and had its first article published on November 4th 1869. Furthermore, this source states that one of the reasons why Nature thrived among other existing journals of its kind is likely due to its liberal values. As of 2018, Nature had an impact factor (based on citations and credibility) of 43.070 which is considered very prestigious and reputtable.

## Navigating Nature Website from the direct webpage
The Nature website's main page consists of different sections including: Featured contents, News & Comment, Latest Reviews and Analysis, Latestest research, Collections, Trending Altmetric and Nature Careers. Each of these sections provide viewers with latest content publications and can be browsed by clicking on the specific hyperlink of interest.

## Our Goal
For the purpose of this project, my group was interested in scraping information on the Latest research page from Nature. Our goal was to explore what kinds of information have been published in Nature journal since its forthcoming. We were also interested in exploring how many articles were published by decades and what keywords, papers and authors were popular. We further created funtions that could extract  articles by keyword, paper and subject; these categories could be further filtered using parameters such as: ***article type***, ***publication year***, ***date range*** and ***relevance***.

## Development and individual contributions
This package was based on the nature.scrape function written for the text mining assigment. Our goal was create a package that would allow a user to search for a topic of interest on nature.com and save the results  along wih other useful information such as the type of article, dates of publication and a url to the actual article to facilitate reading. *We realize  that limiting searching a broader data database would provide more utility and have developed the PubSearch package, which makes use of the entrez api to perform more robust literature searches (see shiny app)*

We both worked on the original scrape function. For the package, Shawn was tasked with  functions to make the package complete.

### Functions
**parameter checks:** 
The aim of these functions are to ensure that the inputs from the user conform to what is required to correctly generate a nature.com url. In most cases, these functions will sorrect common errors such as erroneous white spaces, case issues. The goal was to correct for simple mistakes and break (stop ) and output an error for other cases to ensure that the results the user is getting are those which were expected. 

**explore** 
These are the functions the users interact with. These functions take user defined objects and passes them to the appropriate downstream functions depending on the inputs. 

Blessing was tasked with writting the documentation and use examples for the package. 

We tried to ensure that sufficent documentation was available so that a new user would be able to use the package easily. We also included several examples which highlights different key functionalities in the help files and wrote this vignette. 

**nature.scrape** 
This function does the webscrapping and text mining. The consistency of the organization of nature.com websites made scrappiung the text and categorizing straightforward however, we realize that any refresh/update to the website's major design elements would likely render our package ineffective. 
We aimed to avoid this in the PubSearch package, which is available on github, but is not being turned in for a grade since we dont have enough time to thoroughly test it.

## Getting Started
The package can be installed from github using:
```{r message=FALSE, warning=FALSE}
library(devtools)
#install_github("PHP-2560/r-package-blshli")
library(DiscoverNature)
```

Packages needed to successfully run :

```{r }
#library(rvest)
#library(devtools)
#library(lubridate)
#library(dplyr)
#library(utils)
#library(stringr)
#library(purrr)
#library(xml2)
#library(magrittr)
#library(httr)
```

Specfic use of each package can be found in the NAMESPACE file

## Using explore_keyword
One of the options to search the database is through keywords. By default, only the keyword argument is required like in the code below
```{r }
paper.results <- explore_keyword('cells')
paper.results 
```

This queries the nature.com website for a keyword(s) of interest, in this case ***cells***. The function returns a tibble with publications found in search. 

### Example:
The keyword search query can be modified by article type, publication year or date range, sort preference and page range as shown in the examples below:

**Search by article type**
```{r }
cells_reviews <- explore_keyword('cells', article.types = 'reviews')
cells_reviews
```

**Valid article types:**

research,
reviews,
news,
comments-and-opinion,
news-and-views,
amendments-and-corrections,
correspondenceeditorial,
special-features,
advertorial,
books-and-arts,
protocols,
multimedia,
research-highlights

**By publication range/date**
```{r }
cells_reviews_last5years <- explore_keyword('cells', article.types = 'reviews', publication.range = 'last_5_years')
cells_reviews_last5years
```

Predefined date ranges:
*today*, *last_7_days*, *last_30_days*, *last_year*,*last_2_years*, *last_5_years*. 

**Custom date range searches:**
Users can also search for custom date ranges using either the **l.year** and **u.year** which corresponds to the lower and upper bounds of the year respectively (in 4 digit format).

**NOTE**: if l.year/u.year  and predefined range arguments are supplied together, the predefined.range argument will take priority.
 

```{r }

papersafter2015 <- explore_keyword('cells', article.types = 'reviews',
                                   sort.method = 'date_asc', l.year= 2015)
papersafter2015
```

l.year specifies the lower bound of date range. In other words, it includes articles published ***after*** a specific date/defaults to earliest year.

```{r }
papersbefore2015 <- explore_keyword('cells', article.types = 'reviews',
                                    sort.method = 'date_desc', u.year= 2015)
papersbefore2015

```

u.year specifies the upper bound of date range. In other words, includes articles ***before*** a specific date/defaults to current year. 

**Sort methods**

The results can sorted by date or by relevance.  
For keyword searches, the default sort method is by relevance, while for subject searches the default sort method is in descending order, with the newest papers shown first. The user should be aware of the sorting method since by default only the first page of results are returned. 
In later sections we will describe how to request that multiple pages of results are returned using the *page.range* argument. 

```{r }
explore_keyword('cells', article.types = 'reviews', sort.method = 'relevance')

```

*Sort methods:*
*relevance*, *date_desc*, *date_asc*.

### ***By multiple pages of results***

By default, only the first page of results from a search are returned. ***generally a page query will return ~50 papers***. However, we have included the ability to return multiple pages worth of results from a search. The *page.range* arguments takes a vector of numbers corresponding to the requested pages. As outlined above, the sort method will influence the the order in which papers are ordered in the results and thus the results from the function calls. We sought to include the most appropriate defaults for each search type.   

```{r }
explore_keyword('cells', article.types = 'reviews' , page.range = 1:3)
```


## Using explore_subject
A third option is to search by subject areas curated by nature. This option is most useful for broad searches 

***list.topics()***.  provides the user with an up to date list of available topics to choose from. 

```{r }
topics <- list.topics()
head(topics)
```

Papers in each subject can be searched for using the **explore_subject()** function.
This queries the nature.com website for a subject of interest, in this case *Biochemistry*. The function returns a tibble with publications found in search.

```{r }
paper_by_sub <- explore_subject("Biochemistry",  u.year = 2018)
paper_by_sub 

```

explore_subject( ) search results can be modified by the methods shown for explore_keyword( )

## Using explore_paper
This functions provides an easy way for the user to open an article of interest in a browser without having to manually identify url of paper. 

**Opening paper in a saved search**:
To do this, the user will need to input both a title and resulting tibble from a *explore_keyword* or *explore_subject* search as shown in the code. The explore_paper call searches for the title within the saved search and passes the appropriate url to the browseURL( )

```{r }
#explore_paper(.title = 'c-Myc', res = paper.results)

```

**Opening url directly**:
As an alternative, a url can be supplied directly using the url argument
```{r }
#explore_paper(url = 'https://www.nature.com/articles/s41590-018-0222-z')

```
